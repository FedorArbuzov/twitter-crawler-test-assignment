# Тестовое задание по скачиванию информации о твиттах


В сборке есть postgres для сохранения информации, бекенд для отображения информации, воркер для скачивания на asyncio и redis как очередь для общения между ними. Сервис был протестирован через сваггер.

Что можно еще улучшить:
1. Сделать очередь через rabitmq и отправлять задачи батчами
2. Перезакладывать задачи в очередь с таймаутом если получена ошибка too many requests или что-то такое, сейчас этого нет. У твиттера есть описание своих [rate limit-ов](https://developer.twitter.com/en/docs/twitter-api/rate-limits)
3. Добавить consul для всех ключей
4. Добавить orm и миграции, сейчас работа с базой сделана через asyncpg
5. Покрыть сервис тестами, добавить логи
